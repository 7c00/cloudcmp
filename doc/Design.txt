CloudCmp Design Document

1. Overview

The CloudCmp benchmark suite includes three main components:

  a) Cloud adaptors
  b) Benchmark tasks
  c) Controller

The cloud adaptors abstract away the different native APIs provided by each
cloud provider and provide common interfaces to the benchmark tasks. The
benchmark tasks use the adaptor interfaces to run several local and distributed
benchmark tasks. The controller component exposes a web service interface to
the benchmark user to control the experiments.

Most parts of the suite are implemented in Java, and as a result it is only
(theoretically) supported by cloud providers that offer Java run-time
environment. Some benchmark tasks are implemented in other languages in cases
where language bindings make a difference in performance.

2. Cloud Adaptors

Because the native APIs offered by different cloud providers differ
significantly, we need to provide a common interface to support the same set of
benchmark tasks and ensure fairness. Here we outline the common function
categories that are supported by most providers and are useful for benchmarking
purposes.

  a) Persistent storage functions: these include the basic CRUD (Create, Read,
Update, and Delete) functions provided by the persistent storage services.
Since most providers offer such services as RESTful web services, calls to such
functions are usually directly mapped to HTTP requests.  
  
  b) Network functions: these include the basic network functions that send
probing packets and elastic traffic between instances. They are used by the
benchmark tasks to measure network latency and bandwidth.

  c) Native functions: these include the interfaces to run certain tasks in the
cloud's native runtime environment. For instance, the native interface to send
elastic traffic in Linux-based EC2 instances will use C-based TCP clients
instead of the Java ones. Only a few native functions are currently supported,
and more are on the way.

  d) Management functions: the management functions provide the basic means to
obtain system information (IP address, configuration, etc.), and allow
different instances to communicate with each other. This is important to
orchestrate distributed experiments.

More cloud adaptors can be added for new providers by inheriting the base
CloudAdaptor class and overriding those functions.

3. Benchmark Tasks

Each benchmark task tests one performance aspect of the cloud providers. It
takes some running parameters (e.g., time, # of threads, etc.) and returns some
performance metrics (or an error, if the benchmark task has failed or not
supported by the particular cloud). Some tasks also return the cost consumed by
the tasks, so as to help the users estimating the cost-effectiveness of the
providers.

Regarding the input parameters and return metrics of each benchmark task,
please refer to the README file corresponding to that task in the benchmarks
directory.

4. Controller
